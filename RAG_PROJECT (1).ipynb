{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QJD5wrwHaTlC"
      },
      "outputs": [],
      "source": [
        "# Hi am pakistani. I love my country very much and I am very proud to i am Muslim\n",
        "# 1   2 3  4     5 6  7   8   9       10  11    12 13 14 15  16    17 18 19 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "415iNw5zni7q"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FS7jMBnRoHep"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "0ZWzBENeoUwy",
        "outputId": "bc44772e-cbc8-4e99-8436-89a7fd0f3dcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(genai.list_models())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dP8S9QvBoVw3"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Pakistan zinda bad we love our country\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hm4YVEgHqvbD",
        "outputId": "597156be-b321-46ac-94c7-31c5f850e826"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.03838823,\n",
              " 0.052146558,\n",
              " -0.07062306,\n",
              " -0.037940446,\n",
              " 0.06602876,\n",
              " 0.003412638,\n",
              " 0.011060191,\n",
              " 0.011297473,\n",
              " 0.0088465065,\n",
              " 0.049196165,\n",
              " 0.026362207,\n",
              " 0.029781424,\n",
              " 0.103020616,\n",
              " 0.0018105474,\n",
              " 0.009687083,\n",
              " -0.1145385,\n",
              " 0.053375162,\n",
              " 0.027896093,\n",
              " -0.069912076,\n",
              " 0.033948876,\n",
              " 0.0021454412,\n",
              " -0.06642034,\n",
              " 0.04420987,\n",
              " -0.021766845,\n",
              " -0.05236885,\n",
              " 0.012519431,\n",
              " -0.006010968,\n",
              " -0.005167873,\n",
              " -0.0061494075,\n",
              " 0.0031098027,\n",
              " 0.025889847,\n",
              " 0.056373067,\n",
              " 0.046986956,\n",
              " -0.054916363,\n",
              " 0.02060043,\n",
              " 0.021911908,\n",
              " -0.028752202,\n",
              " 0.022969386,\n",
              " 0.0386514,\n",
              " -0.030484943,\n",
              " -0.089530766,\n",
              " 0.015129875,\n",
              " -0.06397387,\n",
              " 0.047075633,\n",
              " -0.013017894,\n",
              " -0.029871592,\n",
              " -0.0067695505,\n",
              " -0.0074492395,\n",
              " -0.0059240796,\n",
              " 0.03697813,\n",
              " 0.018429233,\n",
              " -0.001360107,\n",
              " -0.011460476,\n",
              " 0.011616342,\n",
              " -0.025911184,\n",
              " -0.05487599,\n",
              " -0.036950245,\n",
              " -0.009039906,\n",
              " 0.011936421,\n",
              " -0.002934238,\n",
              " -0.027310636,\n",
              " 6.6082706e-05,\n",
              " -0.020024965,\n",
              " -0.027493374,\n",
              " 0.002532368,\n",
              " -0.015001376,\n",
              " -0.076121554,\n",
              " 0.032683495,\n",
              " -0.092314504,\n",
              " 0.024527755,\n",
              " -0.0056760833,\n",
              " 0.012404534,\n",
              " -0.054892246,\n",
              " 0.0047428426,\n",
              " 0.027187724,\n",
              " -0.023102688,\n",
              " 0.039532688,\n",
              " -0.04834113,\n",
              " -0.032563046,\n",
              " 0.055642914,\n",
              " -0.06099361,\n",
              " 0.012322463,\n",
              " 0.05332948,\n",
              " 0.044791535,\n",
              " 0.0047311513,\n",
              " 0.03546266,\n",
              " -0.018310213,\n",
              " -0.012843131,\n",
              " -0.03281737,\n",
              " -0.015505913,\n",
              " 0.06564103,\n",
              " 0.004260769,\n",
              " 0.02080681,\n",
              " 0.015551341,\n",
              " 0.03284577,\n",
              " -0.037125297,\n",
              " -0.06909162,\n",
              " -0.12455734,\n",
              " 0.033198744,\n",
              " 0.08457165,\n",
              " -0.014386027,\n",
              " -0.03143208,\n",
              " 0.022384034,\n",
              " -0.004822828,\n",
              " 0.012416186,\n",
              " 0.031697378,\n",
              " -0.1066608,\n",
              " -0.022101557,\n",
              " -0.008450847,\n",
              " -0.0052436255,\n",
              " 0.0067770644,\n",
              " -0.058070153,\n",
              " 0.041524004,\n",
              " -0.028612824,\n",
              " 0.04088967,\n",
              " -0.028240833,\n",
              " -0.034067433,\n",
              " 0.051358417,\n",
              " -0.025877517,\n",
              " 0.028154515,\n",
              " 0.0060459366,\n",
              " 0.026830649,\n",
              " -0.00095973775,\n",
              " 0.017185919,\n",
              " 0.004395111,\n",
              " 0.016280279,\n",
              " 0.0176109,\n",
              " -0.009282771,\n",
              " 0.010105145,\n",
              " -0.03267479,\n",
              " 0.072818495,\n",
              " -0.04778589,\n",
              " 0.01858214,\n",
              " -0.0020002476,\n",
              " -0.05818697,\n",
              " -0.052377947,\n",
              " 0.0286922,\n",
              " -0.014589298,\n",
              " 0.060979374,\n",
              " 0.013860318,\n",
              " -0.0071884138,\n",
              " 0.018080251,\n",
              " -0.07651641,\n",
              " 0.0370387,\n",
              " 0.013180877,\n",
              " -0.021393348,\n",
              " -0.0080846,\n",
              " 0.025077287,\n",
              " -0.06951974,\n",
              " 0.02669913,\n",
              " -0.012492207,\n",
              " 0.01859013,\n",
              " 0.038992975,\n",
              " 0.0051947823,\n",
              " -0.047826,\n",
              " 0.018798502,\n",
              " 0.04019756,\n",
              " -0.039466992,\n",
              " 0.08624624,\n",
              " -0.00062756106,\n",
              " 0.058413763,\n",
              " -0.06800717,\n",
              " 0.029188514,\n",
              " 0.008827655,\n",
              " -0.035301555,\n",
              " -0.025547149,\n",
              " 0.025351042,\n",
              " -0.06396529,\n",
              " -0.024263415,\n",
              " -0.019369712,\n",
              " 0.013893803,\n",
              " -0.02715477,\n",
              " -0.009625998,\n",
              " -0.06395668,\n",
              " -0.058829118,\n",
              " -0.014857789,\n",
              " -0.06285088,\n",
              " -0.019081429,\n",
              " -0.025285693,\n",
              " -0.023807587,\n",
              " 0.10905102,\n",
              " 0.019630715,\n",
              " -0.018424971,\n",
              " -0.051695295,\n",
              " 0.02405902,\n",
              " -0.008708305,\n",
              " 0.013477974,\n",
              " 0.00955763,\n",
              " 0.012669435,\n",
              " 0.052519657,\n",
              " -0.04345961,\n",
              " -0.011683332,\n",
              " -0.01012757,\n",
              " 0.07052994,\n",
              " -0.0055598025,\n",
              " -0.06500708,\n",
              " -0.029050773,\n",
              " -0.020193106,\n",
              " -0.054957137,\n",
              " -0.041815933,\n",
              " 0.029825028,\n",
              " -0.0037500036,\n",
              " -0.04422032,\n",
              " -0.08507198,\n",
              " -0.025203163,\n",
              " -0.022711176,\n",
              " -0.07533748,\n",
              " 0.00038292477,\n",
              " 0.000574007,\n",
              " -0.023213899,\n",
              " -0.05437338,\n",
              " -0.020481981,\n",
              " 0.0309786,\n",
              " -0.03049663,\n",
              " 0.049754348,\n",
              " 0.01301958,\n",
              " 0.059735786,\n",
              " 0.013099316,\n",
              " 0.07402825,\n",
              " 0.0028997941,\n",
              " -0.0031488023,\n",
              " 0.030355373,\n",
              " -0.0345743,\n",
              " 0.027214795,\n",
              " 0.030471744,\n",
              " 0.00409395,\n",
              " -0.006666186,\n",
              " -0.026523612,\n",
              " 0.0037652112,\n",
              " -0.036769453,\n",
              " -0.016134802,\n",
              " 0.033313625,\n",
              " 0.0036026041,\n",
              " 0.016536806,\n",
              " 0.051247668,\n",
              " 0.090472534,\n",
              " 0.010181305,\n",
              " 0.030595109,\n",
              " 0.0070580146,\n",
              " -0.00865541,\n",
              " -0.013374387,\n",
              " 0.010765982,\n",
              " 0.048682828,\n",
              " 0.028028237,\n",
              " -0.020036707,\n",
              " -0.008994092,\n",
              " 0.012286691,\n",
              " 0.040086675,\n",
              " 0.008561659,\n",
              " -0.04989866,\n",
              " -0.03489145,\n",
              " -0.006646721,\n",
              " -0.031492487,\n",
              " -0.021983976,\n",
              " 0.0068252063,\n",
              " -0.055136193,\n",
              " 0.046041407,\n",
              " -0.014977839,\n",
              " 0.018520158,\n",
              " -0.0019085855,\n",
              " 0.036878396,\n",
              " -0.0765386,\n",
              " 0.008701385,\n",
              " -0.059513815,\n",
              " -0.060923666,\n",
              " -0.049235404,\n",
              " 0.004780061,\n",
              " 0.0044634817,\n",
              " 0.08013073,\n",
              " -0.03781426,\n",
              " -0.004155092,\n",
              " -0.07378796,\n",
              " -0.0062083392,\n",
              " 0.00019341962,\n",
              " 0.049237784,\n",
              " 0.016864326,\n",
              " 0.013317688,\n",
              " -0.020757375,\n",
              " 0.011082609,\n",
              " -0.046459932,\n",
              " -0.023551403,\n",
              " -0.0025574379,\n",
              " 0.023846528,\n",
              " -0.03697934,\n",
              " -0.018832024,\n",
              " -0.05554495,\n",
              " 0.017728858,\n",
              " -0.008121325,\n",
              " -0.021077035,\n",
              " -0.006830344,\n",
              " 0.03167001,\n",
              " 0.02122792,\n",
              " 0.053463276,\n",
              " -0.051008683,\n",
              " 0.033604734,\n",
              " 0.0053696907,\n",
              " 0.043874938,\n",
              " 0.0068859165,\n",
              " 0.035119798,\n",
              " -0.009732238,\n",
              " 0.006822771,\n",
              " 0.035985652,\n",
              " 0.010248646,\n",
              " 0.021891562,\n",
              " 0.032525573,\n",
              " 0.011882014,\n",
              " 0.05660894,\n",
              " -0.013528444,\n",
              " -0.013231257,\n",
              " -0.045601033,\n",
              " 0.048486833,\n",
              " 0.061330978,\n",
              " -0.013769018,\n",
              " -0.021071164,\n",
              " -0.05462211,\n",
              " -0.01022884,\n",
              " -0.16075553,\n",
              " 0.0055632093,\n",
              " -0.005055581,\n",
              " -0.0068281684,\n",
              " -0.03442759,\n",
              " 0.02271425,\n",
              " 0.016652118,\n",
              " 0.002752376,\n",
              " 0.043466292,\n",
              " 0.02711752,\n",
              " -0.016791742,\n",
              " -0.048889656,\n",
              " 0.03908195,\n",
              " -0.022985088,\n",
              " 0.012583863,\n",
              " 0.005726204,\n",
              " 0.023895126,\n",
              " -0.05023696,\n",
              " -0.00048284858,\n",
              " 0.008326804,\n",
              " -0.03993198,\n",
              " 0.013789181,\n",
              " 0.047209363,\n",
              " 0.027224733,\n",
              " -0.025249159,\n",
              " -0.0023370015,\n",
              " 0.043043554,\n",
              " 0.021095976,\n",
              " 0.03354987,\n",
              " -0.030191306,\n",
              " 0.02248958,\n",
              " -0.028729452,\n",
              " 0.05607367,\n",
              " -0.009501291,\n",
              " -0.023586508,\n",
              " 0.08498721,\n",
              " 0.0575211,\n",
              " -0.00075478735,\n",
              " -0.011939774,\n",
              " 0.0003264734,\n",
              " 0.060069848,\n",
              " -0.0073553207,\n",
              " 0.033479355,\n",
              " 0.0030075137,\n",
              " -0.01904192,\n",
              " -0.005860383,\n",
              " 0.023575183,\n",
              " 0.05215699,\n",
              " -5.4912136e-05,\n",
              " -0.060488857,\n",
              " -0.023957102,\n",
              " 0.012998325,\n",
              " 0.03517663,\n",
              " -0.035629902,\n",
              " 0.0369,\n",
              " 0.008402149,\n",
              " 0.001765194,\n",
              " 0.0023059861,\n",
              " 0.04675764,\n",
              " -0.04476126,\n",
              " -0.0069735753,\n",
              " -0.0002626759,\n",
              " 0.023913743,\n",
              " -0.02967791,\n",
              " 0.00031710474,\n",
              " -0.010220715,\n",
              " 0.009249499,\n",
              " 0.020453123,\n",
              " -0.03715475,\n",
              " 0.047895074,\n",
              " 0.001733521,\n",
              " 0.0037312186,\n",
              " 0.022507915,\n",
              " 0.06591765,\n",
              " -0.0115289455,\n",
              " 0.013562781,\n",
              " 0.057814762,\n",
              " 0.04246558,\n",
              " 5.7039684e-05,\n",
              " 0.033612076,\n",
              " -0.042697903,\n",
              " 0.0644634,\n",
              " -9.151293e-05,\n",
              " 0.037152737,\n",
              " -0.0011938581,\n",
              " -0.027302312,\n",
              " 0.09659006,\n",
              " 0.0012583006,\n",
              " -0.010336961,\n",
              " -0.061051127,\n",
              " 0.01347184,\n",
              " -0.0049233683,\n",
              " 0.008797497,\n",
              " 0.03161731,\n",
              " -0.03648881,\n",
              " -0.009932623,\n",
              " -0.07835084,\n",
              " 4.2173e-05,\n",
              " -0.03334824,\n",
              " 0.014768315,\n",
              " -0.015830249,\n",
              " 0.021433732,\n",
              " -0.025502263,\n",
              " 0.0038483543,\n",
              " -0.016326146,\n",
              " -0.014174781,\n",
              " -0.016782146,\n",
              " -0.020667074,\n",
              " 0.01614993,\n",
              " -0.08426387,\n",
              " -0.03154883,\n",
              " 0.01654426,\n",
              " 0.0670697,\n",
              " 0.042512123,\n",
              " 0.062353604,\n",
              " -0.030913549,\n",
              " 0.013138386,\n",
              " 0.026835408,\n",
              " 0.0110793365,\n",
              " -0.0218443,\n",
              " 0.026536738,\n",
              " -0.0064630304,\n",
              " -0.022492763,\n",
              " -0.035576217,\n",
              " -0.037078027,\n",
              " 0.01286653,\n",
              " -0.00037669428,\n",
              " 0.04966357,\n",
              " -0.0024665396,\n",
              " 0.0146915335,\n",
              " 0.06098033,\n",
              " -0.029980283,\n",
              " 0.0008697028,\n",
              " 0.064677365,\n",
              " -0.00428359,\n",
              " -0.01547883,\n",
              " -0.025234092,\n",
              " 0.025209295,\n",
              " -0.002039264,\n",
              " 0.03444799,\n",
              " -0.0022913783,\n",
              " 0.023588978,\n",
              " -0.045668975,\n",
              " 0.04170248,\n",
              " -0.044887327,\n",
              " -0.021114206,\n",
              " 0.045086056,\n",
              " 0.015677046,\n",
              " -0.0041803983,\n",
              " -0.02905689,\n",
              " -0.013574269,\n",
              " 0.070722766,\n",
              " -0.0015028456,\n",
              " -0.019128142,\n",
              " -0.026981374,\n",
              " -0.0075038965,\n",
              " 0.009927641,\n",
              " 0.011850352,\n",
              " -0.040748272,\n",
              " 0.029269002,\n",
              " 0.014578034,\n",
              " 0.04644106,\n",
              " -0.06513363,\n",
              " -0.047762387,\n",
              " 0.005994523,\n",
              " -0.016654402,\n",
              " -0.046001986,\n",
              " 0.033784177,\n",
              " -0.0059721963,\n",
              " -0.070746414,\n",
              " -0.016943036,\n",
              " -0.0011437157,\n",
              " 0.029320652,\n",
              " 0.08227695,\n",
              " 0.025052816,\n",
              " 0.0022991449,\n",
              " 0.011448173,\n",
              " -0.008304278,\n",
              " 0.019583032,\n",
              " -0.014954232,\n",
              " 0.030788248,\n",
              " 0.0029797773,\n",
              " -0.03788128,\n",
              " 0.03724129,\n",
              " 0.05528784,\n",
              " -0.034972087,\n",
              " -0.0019545844,\n",
              " -0.05261343,\n",
              " -0.056895804,\n",
              " 0.044773314,\n",
              " -0.063213706,\n",
              " -0.043816824,\n",
              " 0.0905643,\n",
              " -0.04863921,\n",
              " 0.046625808,\n",
              " 0.035758417,\n",
              " 0.011668098,\n",
              " 0.0079242475,\n",
              " -0.03298972,\n",
              " -0.011208986,\n",
              " -0.081154466,\n",
              " -0.0031484948,\n",
              " -0.017065778,\n",
              " 0.024816861,\n",
              " -0.06621424,\n",
              " -0.039437614,\n",
              " 0.042017188,\n",
              " -0.00050168845,\n",
              " 0.018247671,\n",
              " -0.024270063,\n",
              " -0.030748807,\n",
              " 0.02384947,\n",
              " 0.008581831,\n",
              " -0.032525916,\n",
              " -0.003901744,\n",
              " 0.036596827,\n",
              " 0.022501571,\n",
              " 0.014229588,\n",
              " -0.0061629214,\n",
              " 0.047474425,\n",
              " 0.01413304,\n",
              " 0.0031166582,\n",
              " 0.040364627,\n",
              " -0.019387295,\n",
              " 0.014101074,\n",
              " -0.008786798,\n",
              " -0.029672347,\n",
              " 0.02951629,\n",
              " 0.02604202,\n",
              " 0.04345717,\n",
              " -0.060620695,\n",
              " 0.025450386,\n",
              " -0.015682898,\n",
              " 0.028722597,\n",
              " -0.008685122,\n",
              " -0.010794636,\n",
              " -0.012771901,\n",
              " -0.0011217573,\n",
              " 0.005098702,\n",
              " -0.04036902,\n",
              " -0.02358411,\n",
              " -0.0033144718,\n",
              " -0.0679191,\n",
              " -0.020438666,\n",
              " -0.019104637,\n",
              " -0.03788486,\n",
              " 0.0044292295,\n",
              " 0.022491189,\n",
              " 0.0033494795,\n",
              " -0.046392314,\n",
              " 0.03587325,\n",
              " 0.04138297,\n",
              " 0.0287248,\n",
              " -0.0068671093,\n",
              " -0.0005605311,\n",
              " 0.011639575,\n",
              " 0.024345625,\n",
              " -0.060927104,\n",
              " 0.04197428,\n",
              " 0.015342221,\n",
              " -0.018747458,\n",
              " 0.008443097,\n",
              " 0.055946324,\n",
              " -0.005637669,\n",
              " 0.054343686,\n",
              " 0.018478725,\n",
              " 0.037477393,\n",
              " -0.04967184,\n",
              " 0.02941245,\n",
              " 0.010871435,\n",
              " 0.032436363,\n",
              " 0.0059494562,\n",
              " 0.04422599,\n",
              " -0.006740689,\n",
              " -0.02163518,\n",
              " 0.022332964,\n",
              " 0.017083554,\n",
              " -0.0512461,\n",
              " -0.05113343,\n",
              " -0.0320302,\n",
              " -0.048574947,\n",
              " -0.017281223,\n",
              " 0.007265277,\n",
              " -0.025888035,\n",
              " 0.0499955,\n",
              " -0.028761506,\n",
              " 0.047641512,\n",
              " 0.006997258,\n",
              " -0.055606503,\n",
              " -0.117244676,\n",
              " -0.010426683,\n",
              " -0.028365433,\n",
              " -0.018504485,\n",
              " -0.009055795,\n",
              " -0.014238359,\n",
              " -0.015719526,\n",
              " -0.03149241,\n",
              " -0.003400495,\n",
              " -0.012937613,\n",
              " -0.018243145,\n",
              " -0.0144358035,\n",
              " -0.0056894287,\n",
              " 0.054088052,\n",
              " 0.011907005,\n",
              " -0.002125421,\n",
              " -0.01782156,\n",
              " 0.0037183985,\n",
              " -0.054034688,\n",
              " -0.012775008,\n",
              " -0.020216625,\n",
              " -0.023934435,\n",
              " 0.017653301,\n",
              " 0.0046870117,\n",
              " 0.027500125,\n",
              " 0.012845098,\n",
              " 0.022624854,\n",
              " 0.03215435,\n",
              " -0.016278284,\n",
              " 0.017207153,\n",
              " 0.022287257,\n",
              " -0.004011496,\n",
              " -0.021268496,\n",
              " 0.018312145,\n",
              " -0.003118074,\n",
              " -0.0376296,\n",
              " -0.023842245,\n",
              " 0.025278052,\n",
              " 0.0063156355,\n",
              " -0.03015189,\n",
              " 0.031874474,\n",
              " -0.008299831,\n",
              " -0.0011517438,\n",
              " 0.0062523056,\n",
              " -0.00044700058,\n",
              " -0.016225612,\n",
              " -0.032361522,\n",
              " 0.020232819,\n",
              " -0.011365004,\n",
              " -0.025918007,\n",
              " 0.033456538,\n",
              " -0.0038194235,\n",
              " -0.04559527,\n",
              " 0.0091817845,\n",
              " -0.05172906,\n",
              " 0.0042541544,\n",
              " -0.020796109,\n",
              " 0.041575905,\n",
              " 0.022975706,\n",
              " -0.021847228,\n",
              " -0.007324385,\n",
              " -0.011522168,\n",
              " -0.055374276,\n",
              " 0.026773449,\n",
              " -0.020385416,\n",
              " 0.03198812,\n",
              " -0.02696582,\n",
              " 0.02701983,\n",
              " 0.032033257,\n",
              " -0.025706427,\n",
              " -0.028448839,\n",
              " 0.0704481,\n",
              " -0.023736434,\n",
              " -0.047385562,\n",
              " 0.033373505,\n",
              " -0.010090002,\n",
              " -0.027287053,\n",
              " -0.015427962,\n",
              " -0.04851017,\n",
              " 0.036831185,\n",
              " -0.012953718,\n",
              " 0.022658195,\n",
              " -0.021795256,\n",
              " 0.02059936,\n",
              " 0.024475915,\n",
              " 0.00055408303,\n",
              " -0.026111007,\n",
              " -0.03636221,\n",
              " -0.016248602,\n",
              " 0.030392338,\n",
              " 0.07902486,\n",
              " -0.024101842,\n",
              " 0.0055876803,\n",
              " -0.008215156,\n",
              " -0.023136614,\n",
              " -0.030492572,\n",
              " -0.0022403337,\n",
              " -0.035763245,\n",
              " -0.03326536,\n",
              " 0.0021086684,\n",
              " -0.010088928,\n",
              " -0.008121419,\n",
              " 0.0019507741,\n",
              " -0.073499575,\n",
              " 0.049395718,\n",
              " 0.023999428,\n",
              " -0.0007134775,\n",
              " 0.032879937,\n",
              " -0.00640119,\n",
              " 0.02869106,\n",
              " 0.013808199,\n",
              " 0.023221033,\n",
              " -0.01590115,\n",
              " 0.023822999,\n",
              " 0.08655637,\n",
              " -0.04039015,\n",
              " 0.03261114,\n",
              " 0.017652059,\n",
              " 0.03452416,\n",
              " 0.02047702,\n",
              " -0.039462328,\n",
              " -0.04694545,\n",
              " 0.038026884,\n",
              " -0.047012918,\n",
              " 0.074192934,\n",
              " 0.05681196,\n",
              " 0.0008074619,\n",
              " -0.046055894,\n",
              " 0.05716265,\n",
              " -0.019507777,\n",
              " -0.031380996,\n",
              " -0.024576735,\n",
              " -0.0037123791,\n",
              " -0.03486795,\n",
              " 0.02585528,\n",
              " 0.05651957,\n",
              " -0.054238588,\n",
              " -0.06553499,\n",
              " -0.023791313,\n",
              " -0.0122753875,\n",
              " 0.009531079,\n",
              " -0.031291775,\n",
              " -0.045523264,\n",
              " -0.015830627,\n",
              " -0.04805145,\n",
              " -0.059642047,\n",
              " 0.029825516,\n",
              " 0.05650545,\n",
              " 0.019484732,\n",
              " 0.073890746,\n",
              " 0.009196346,\n",
              " 0.030793106,\n",
              " -0.03390429,\n",
              " 0.024764318,\n",
              " 0.061629165,\n",
              " -0.043743283,\n",
              " 0.0106486445,\n",
              " 0.010411605,\n",
              " 0.0031037293,\n",
              " -0.05513253,\n",
              " -0.04937317,\n",
              " 0.004930977,\n",
              " -0.008528327]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['embedding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rBwCIDyq3xy",
        "outputId": "0ce78cb5-f3d7-453a-b8a6-523564ed001d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result['embedding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g5RZRlSdrJ9x"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"Can you define python in langchain\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RJncl_B4gKBJ",
        "outputId": "292b041a-221f-425c-e00a-05b28e631c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.026137933, 0.0020330907, -0.074944444, -0.0044 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ],
      "source": [
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLenMvcpgP_I"
      },
      "source": [
        "# ***Building Vector Stores & Retreival using Chroma DB and Langchain***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7JktimSqgZPI",
        "outputId": "da4d7d93-900b-44bf-e65e-5045fdc5d77d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3L4zEqtdgme7"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wBnhmZ26hc1g"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oUi2JlPBhdiq"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nla6_Ntln6RL",
        "outputId": "5d20a16f-4e90-4e38-ef8a-af6c4d2c9ef2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.040674030780792236,\n",
              " 0.006255019456148148,\n",
              " -0.013568978756666183,\n",
              " -0.0003686861018650234,\n",
              " 0.04303165152668953,\n",
              " 0.04935013875365257,\n",
              " -0.013514830730855465,\n",
              " -0.027903610840439796,\n",
              " -0.03995805233716965,\n",
              " -0.006844368763267994,\n",
              " 0.0013024156214669347,\n",
              " -0.009539234451949596,\n",
              " 0.0705987736582756,\n",
              " -0.009862210601568222,\n",
              " 0.03167127072811127,\n",
              " -0.02663198858499527,\n",
              " -0.018167555332183838,\n",
              " -0.005245935637503862,\n",
              " -0.14866198599338531,\n",
              " -0.01596848852932453,\n",
              " 0.02811194583773613,\n",
              " -0.0018506837077438831,\n",
              " -0.025303209200501442,\n",
              " -0.01434125192463398,\n",
              " -0.03104301728308201,\n",
              " -0.07088255137205124,\n",
              " 0.011673162691295147,\n",
              " 0.008746510371565819,\n",
              " 0.003015926806256175,\n",
              " -0.010475549846887589,\n",
              " -6.184780795592815e-05,\n",
              " -0.0014338439796119928,\n",
              " -0.03641575202345848,\n",
              " -0.0519932359457016,\n",
              " -0.02123081497848034,\n",
              " 0.03613690286874771,\n",
              " -0.03694721683859825,\n",
              " 0.06530386954545975,\n",
              " 0.031148776412010193,\n",
              " -0.05865824222564697,\n",
              " -0.033094197511672974,\n",
              " -0.002400598954409361,\n",
              " -0.039360735565423965,\n",
              " 0.001522441511042416,\n",
              " 0.03487030044198036,\n",
              " 0.0026657148264348507,\n",
              " -0.0058933584950864315,\n",
              " 0.020132659003138542,\n",
              " -0.0036536972038447857,\n",
              " 0.008130554109811783,\n",
              " -0.009108034893870354,\n",
              " -0.03555028885602951,\n",
              " -0.014387637376785278,\n",
              " 0.0020767864771187305,\n",
              " -0.047531772404909134,\n",
              " -0.023021064698696136,\n",
              " 0.02736302837729454,\n",
              " -0.026102488860487938,\n",
              " 0.08498480916023254,\n",
              " -0.009469239041209221,\n",
              " 0.0319310761988163,\n",
              " -0.0018667412223294377,\n",
              " 0.059389110654592514,\n",
              " -0.0035042506642639637,\n",
              " 0.020587773993611336,\n",
              " -0.03917128965258598,\n",
              " 0.03360649570822716,\n",
              " 0.015973566100001335,\n",
              " -0.0738484337925911,\n",
              " -0.02538050338625908,\n",
              " -0.02277788706123829,\n",
              " 0.05237537994980812,\n",
              " 0.011328230611979961,\n",
              " -0.03981751948595047,\n",
              " -0.0006608059629797935,\n",
              " -0.008069388568401337,\n",
              " 0.007512678857892752,\n",
              " -0.04804745689034462,\n",
              " 0.03459799289703369,\n",
              " 0.08978776633739471,\n",
              " -0.07167279720306396,\n",
              " 0.022603409364819527,\n",
              " 0.08019706606864929,\n",
              " 0.00940668024122715,\n",
              " 0.03418527916073799,\n",
              " -0.015340480022132397,\n",
              " -0.03552362322807312,\n",
              " -0.03181988373398781,\n",
              " -0.05383983999490738,\n",
              " -0.04403817653656006,\n",
              " 0.05618930980563164,\n",
              " -0.02780766971409321,\n",
              " -0.02107255905866623,\n",
              " -0.018637580797076225,\n",
              " 0.0897323489189148,\n",
              " -0.06604108214378357,\n",
              " -0.09660559147596359,\n",
              " -0.05220397189259529,\n",
              " 0.07147490233182907,\n",
              " 0.06639932841062546,\n",
              " 0.004779261536896229,\n",
              " -0.03112303651869297,\n",
              " 0.0008881306857801974,\n",
              " 0.01845836080610752,\n",
              " 0.0274297297000885,\n",
              " 0.0004622933629434556,\n",
              " -0.03492116928100586,\n",
              " -0.004169788211584091,\n",
              " -0.021554481238126755,\n",
              " -0.02542758919298649,\n",
              " -0.02286696434020996,\n",
              " -0.03512721508741379,\n",
              " 0.0026910000015050173,\n",
              " -0.028166597709059715,\n",
              " 0.004026286769658327,\n",
              " -0.00791264045983553,\n",
              " -0.024778082966804504,\n",
              " 0.015024474821984768,\n",
              " -0.010839731432497501,\n",
              " 0.009473622776567936,\n",
              " 0.056382134556770325,\n",
              " 0.021171119064092636,\n",
              " -0.008079694584012032,\n",
              " 0.025672005489468575,\n",
              " 0.028384380042552948,\n",
              " 0.020231332629919052,\n",
              " 0.0428866408765316,\n",
              " -0.0007346387719735503,\n",
              " -0.03555949404835701,\n",
              " -0.05524420365691185,\n",
              " -0.014625327661633492,\n",
              " 0.009426695294678211,\n",
              " 0.010897071100771427,\n",
              " -0.003945027478039265,\n",
              " 0.022394057363271713,\n",
              " -0.024528535082936287,\n",
              " 0.0876956656575203,\n",
              " 0.04642253741621971,\n",
              " -0.030577486380934715,\n",
              " 0.03828105702996254,\n",
              " 0.03191431239247322,\n",
              " -0.04186468943953514,\n",
              " -0.06275169551372528,\n",
              " 0.014168639667332172,\n",
              " -0.01498769223690033,\n",
              " -0.024832768365740776,\n",
              " 0.027766933664679527,\n",
              " -0.0004999113152734935,\n",
              " -0.025478815659880638,\n",
              " -0.03067292645573616,\n",
              " -0.027004195377230644,\n",
              " 0.005373257678002119,\n",
              " -0.005426143296062946,\n",
              " -0.013760142959654331,\n",
              " 0.047259990125894547,\n",
              " -3.351004352225573e-06,\n",
              " 0.011196448467671871,\n",
              " 0.0331735797226429,\n",
              " 0.04530906677246094,\n",
              " 0.026219498366117477,\n",
              " -0.03507794439792633,\n",
              " 0.013839093036949635,\n",
              " -0.02348119020462036,\n",
              " 0.028220539912581444,\n",
              " -0.039287421852350235,\n",
              " 0.023950839415192604,\n",
              " -0.02938219904899597,\n",
              " -0.003724222769960761,\n",
              " 0.03192543610930443,\n",
              " 0.0069425287656486034,\n",
              " -0.02548467367887497,\n",
              " -0.03700289875268936,\n",
              " -0.053304944187402725,\n",
              " -0.06592298299074173,\n",
              " -0.01140379998832941,\n",
              " 0.07297323644161224,\n",
              " -0.010483955964446068,\n",
              " -0.04604703560471535,\n",
              " -0.12386089563369751,\n",
              " -0.05467037111520767,\n",
              " 0.03335092216730118,\n",
              " 0.013243228197097778,\n",
              " -0.05039249360561371,\n",
              " -0.008832715451717377,\n",
              " 0.06478633731603622,\n",
              " 0.04017411917448044,\n",
              " 0.0036366560962051153,\n",
              " -0.026531219482421875,\n",
              " -0.015908753499388695,\n",
              " 0.006120656616985798,\n",
              " -0.01062320638448,\n",
              " 0.005162350367754698,\n",
              " 0.032537247985601425,\n",
              " -0.042312879115343094,\n",
              " 0.017654040828347206,\n",
              " 0.05063820630311966,\n",
              " 0.042538005858659744,\n",
              " -0.03213687241077423,\n",
              " -0.038917768746614456,\n",
              " 0.010565686970949173,\n",
              " -0.010164313018321991,\n",
              " -0.029124340042471886,\n",
              " 0.028939809650182724,\n",
              " -0.046825725585222244,\n",
              " -0.04041363671422005,\n",
              " -0.02851947396993637,\n",
              " -0.05352668836712837,\n",
              " -0.023540807887911797,\n",
              " -0.05905939266085625,\n",
              " 0.006182074546813965,\n",
              " 0.0236660148948431,\n",
              " 0.01643635518848896,\n",
              " -0.055969204753637314,\n",
              " -0.052113115787506104,\n",
              " 0.005142379552125931,\n",
              " 0.015834525227546692,\n",
              " 0.07765226811170578,\n",
              " 0.014419138431549072,\n",
              " 0.014757545664906502,\n",
              " -0.016682716086506844,\n",
              " 0.035169124603271484,\n",
              " -0.012445286847651005,\n",
              " 0.04094401374459267,\n",
              " -0.0004567909345496446,\n",
              " 0.03075295127928257,\n",
              " 0.015191249549388885,\n",
              " 0.0008787462138570845,\n",
              " 0.011183375492691994,\n",
              " -0.02541988343000412,\n",
              " -0.01335611566901207,\n",
              " 0.04078405350446701,\n",
              " 0.00097758905030787,\n",
              " -0.027971843257546425,\n",
              " 0.03310989588499069,\n",
              " -0.036995869129896164,\n",
              " 0.07041022926568985,\n",
              " 0.038847681134939194,\n",
              " 0.011135242879390717,\n",
              " 0.0178934745490551,\n",
              " -0.06709057837724686,\n",
              " -0.018150683492422104,\n",
              " -0.004681224934756756,\n",
              " -0.020785439759492874,\n",
              " -0.0015118676237761974,\n",
              " -0.01593458652496338,\n",
              " 0.008007141761481762,\n",
              " 0.056374192237854004,\n",
              " 0.018349969759583473,\n",
              " -0.01836358942091465,\n",
              " -0.03326503559947014,\n",
              " -0.062389075756073,\n",
              " 0.012848050333559513,\n",
              " -0.0030290777795016766,\n",
              " 0.00806711707264185,\n",
              " -0.06129119545221329,\n",
              " -0.009198661893606186,\n",
              " 0.0034411519300192595,\n",
              " -0.05829843878746033,\n",
              " 0.017203867435455322,\n",
              " 0.07828714698553085,\n",
              " 0.02788754366338253,\n",
              " -0.05472508445382118,\n",
              " -0.0053860764019191265,\n",
              " -0.04209680110216141,\n",
              " -0.057854652404785156,\n",
              " -0.06215570494532585,\n",
              " -0.037162765860557556,\n",
              " -0.026187805458903313,\n",
              " 0.013729006983339787,\n",
              " 0.00522513035684824,\n",
              " 0.007254887372255325,\n",
              " 0.007314743008464575,\n",
              " -0.044295214116573334,\n",
              " 0.012690248899161816,\n",
              " 0.0015951964305713773,\n",
              " -0.020993180572986603,\n",
              " -0.028973281383514404,\n",
              " 0.01797867938876152,\n",
              " -0.03705243021249771,\n",
              " 0.016344338655471802,\n",
              " 0.047140851616859436,\n",
              " -0.0045312875881791115,\n",
              " 0.020043889060616493,\n",
              " -0.04180380329489708,\n",
              " 0.008862539194524288,\n",
              " 0.011784982867538929,\n",
              " 0.012936141341924667,\n",
              " 0.04847110062837601,\n",
              " 0.020518505945801735,\n",
              " -0.04009382799267769,\n",
              " 0.004235445521771908,\n",
              " -0.015121255069971085,\n",
              " -0.017107676714658737,\n",
              " -0.0022628495935350657,\n",
              " 0.03131377324461937,\n",
              " 0.058326173573732376,\n",
              " 0.047612544149160385,\n",
              " 0.0008990900823846459,\n",
              " 0.012505724094808102,\n",
              " 0.0234519150108099,\n",
              " 0.011617792770266533,\n",
              " 0.0089767687022686,\n",
              " 0.012201692909002304,\n",
              " 0.05818939581513405,\n",
              " 0.07964139431715012,\n",
              " 0.02628134936094284,\n",
              " 0.0035562783014029264,\n",
              " -0.06586579233407974,\n",
              " -0.06682974845170975,\n",
              " -0.004343168810009956,\n",
              " 0.024766702204942703,\n",
              " -0.045907892286777496,\n",
              " -0.024228105321526527,\n",
              " -0.04364803433418274,\n",
              " -0.01721922867000103,\n",
              " -0.014083858579397202,\n",
              " -0.08534359931945801,\n",
              " -0.022292688488960266,\n",
              " -0.035723213106393814,\n",
              " -0.05347568914294243,\n",
              " 0.04860648512840271,\n",
              " -0.024981264024972916,\n",
              " -0.05546209588646889,\n",
              " -0.02599288523197174,\n",
              " 0.059800885617733,\n",
              " 0.027545634657144547,\n",
              " 0.010634008795022964,\n",
              " 0.030378857627511024,\n",
              " -0.06266247481107712,\n",
              " -0.02802923507988453,\n",
              " -0.0164673812687397,\n",
              " -0.00466604670509696,\n",
              " 0.0068775867111980915,\n",
              " -0.04135647043585777,\n",
              " 0.013757770881056786,\n",
              " 0.030090903863310814,\n",
              " -0.051660291850566864,\n",
              " 0.035671450197696686,\n",
              " 0.05833543464541435,\n",
              " 0.030305322259664536,\n",
              " 0.030703585594892502,\n",
              " 0.045433782041072845,\n",
              " 0.035327911376953125,\n",
              " 0.04064740985631943,\n",
              " -0.02929910458624363,\n",
              " 0.0028224694542586803,\n",
              " 0.04217402637004852,\n",
              " 0.017522307112812996,\n",
              " -0.02317088656127453,\n",
              " -0.012836667709052563,\n",
              " 0.016060883179306984,\n",
              " 0.07096286863088608,\n",
              " 0.022300882264971733,\n",
              " -0.030652055516839027,\n",
              " -0.02046220190823078,\n",
              " -0.008860406465828419,\n",
              " 0.044191617518663406,\n",
              " 0.012760547921061516,\n",
              " 0.017109554260969162,\n",
              " 0.00567222386598587,\n",
              " 0.020018693059682846,\n",
              " -0.015990694984793663,\n",
              " -0.03650399297475815,\n",
              " -0.010141105391085148,\n",
              " -0.024074191227555275,\n",
              " 0.03260262683033943,\n",
              " 0.01904658041894436,\n",
              " 0.03513059765100479,\n",
              " -0.012212435714900494,\n",
              " 0.0036663140635937452,\n",
              " -0.0070173488929867744,\n",
              " -0.03424908220767975,\n",
              " 0.036729518324136734,\n",
              " 0.01946347951889038,\n",
              " -0.00860413908958435,\n",
              " -0.04971911385655403,\n",
              " -0.059182457625865936,\n",
              " -0.002848780946806073,\n",
              " 0.031969111412763596,\n",
              " -0.026185661554336548,\n",
              " 0.05550776794552803,\n",
              " -0.004006619565188885,\n",
              " -0.051209691911935806,\n",
              " 0.06815080344676971,\n",
              " -0.05306592956185341,\n",
              " 0.020680462941527367,\n",
              " -0.07201379537582397,\n",
              " -0.01924624852836132,\n",
              " 0.005424595437943935,\n",
              " -0.043159838765859604,\n",
              " -0.004355010110884905,\n",
              " -0.0022963096853345633,\n",
              " 0.028794437646865845,\n",
              " 0.030889587476849556,\n",
              " -0.007004606071859598,\n",
              " 0.07111821323633194,\n",
              " -0.013412009924650192,\n",
              " -0.014901253394782543,\n",
              " 0.014481945894658566,\n",
              " -0.038996364921331406,\n",
              " -0.03584769740700722,\n",
              " -0.0066221775487065315,\n",
              " 0.008168015629053116,\n",
              " -0.03866076096892357,\n",
              " -0.024964667856693268,\n",
              " -0.03399388864636421,\n",
              " 0.07047809660434723,\n",
              " -0.002807113341987133,\n",
              " -0.0026940142270177603,\n",
              " -0.02858911268413067,\n",
              " 0.06441131234169006,\n",
              " 0.022924337536096573,\n",
              " -0.038946185261011124,\n",
              " -0.005655820947140455,\n",
              " -0.05000632628798485,\n",
              " -0.014447260648012161,\n",
              " -0.002026891801506281,\n",
              " 0.0030106124468147755,\n",
              " 0.05433937534689903,\n",
              " 0.0038927753921598196,\n",
              " 0.01058945618569851,\n",
              " -0.020083194598555565,\n",
              " 0.06434295326471329,\n",
              " -0.037731949239969254,\n",
              " 0.019364971667528152,\n",
              " -0.01708812639117241,\n",
              " -0.007275398354977369,\n",
              " 0.006923719309270382,\n",
              " 0.03294694796204567,\n",
              " 0.008821401745080948,\n",
              " -0.035904500633478165,\n",
              " 0.023028215393424034,\n",
              " -0.028629709035158157,\n",
              " -0.012202284298837185,\n",
              " -0.07996783405542374,\n",
              " 0.009951084852218628,\n",
              " -0.018842991441488266,\n",
              " 0.04279767721891403,\n",
              " 0.0063218362629413605,\n",
              " -0.020923594012856483,\n",
              " 0.01167957205325365,\n",
              " 0.02149077132344246,\n",
              " 0.04855334386229515,\n",
              " 0.01931636407971382,\n",
              " -0.00798702146857977,\n",
              " 0.005307495128363371,\n",
              " -0.010870776139199734,\n",
              " 0.02465776912868023,\n",
              " -0.05784374848008156,\n",
              " -0.012009432539343834,\n",
              " -0.0010353594552725554,\n",
              " 0.001357968314550817,\n",
              " 0.03233030438423157,\n",
              " -0.03482642024755478,\n",
              " -0.04115253686904907,\n",
              " -0.0016379851149395108,\n",
              " -0.016736943274736404,\n",
              " 0.03030269965529442,\n",
              " 0.0070823547430336475,\n",
              " 0.013011662289500237,\n",
              " 0.0013094530440866947,\n",
              " -0.023420250043272972,\n",
              " 0.04642616957426071,\n",
              " 0.04938816651701927,\n",
              " 0.011798360385000706,\n",
              " -0.045309584587812424,\n",
              " 0.009469387121498585,\n",
              " -0.005720063112676144,\n",
              " -0.005492646712809801,\n",
              " 0.07672107964754105,\n",
              " 0.05767561495304108,\n",
              " -0.016651729121804237,\n",
              " 0.01272104773670435,\n",
              " -0.028916891664266586,\n",
              " -0.01569833792746067,\n",
              " 0.013438977301120758,\n",
              " -0.04521883279085159,\n",
              " -0.04580063745379448,\n",
              " -0.06875801086425781,\n",
              " -0.008748088032007217,\n",
              " 0.0034978643525391817,\n",
              " -0.05619722977280617,\n",
              " -0.046840690076351166,\n",
              " 0.049902353435754776,\n",
              " 0.03386502340435982,\n",
              " -0.008411991409957409,\n",
              " -0.003451331052929163,\n",
              " -0.02074151486158371,\n",
              " 0.07574094086885452,\n",
              " -0.01795017346739769,\n",
              " 0.015205703675746918,\n",
              " 0.020769039168953896,\n",
              " -0.0004893033183179796,\n",
              " -0.04977618157863617,\n",
              " -0.06083740293979645,\n",
              " -0.011869067326188087,\n",
              " 0.04016096889972687,\n",
              " -0.0056722043082118034,\n",
              " -0.02773195691406727,\n",
              " 0.01636294275522232,\n",
              " 0.01701270416378975,\n",
              " 0.03908716142177582,\n",
              " -0.015088760294020176,\n",
              " -0.03776533156633377,\n",
              " -0.02017400600016117,\n",
              " -0.05718950182199478,\n",
              " -0.04964404180645943,\n",
              " -0.008687540888786316,\n",
              " -0.00674031674861908,\n",
              " -0.009721371345221996,\n",
              " 0.00877001229673624,\n",
              " -0.04894879087805748,\n",
              " 0.029544781893491745,\n",
              " 0.0656760111451149,\n",
              " 0.01786809228360653,\n",
              " 0.03679507598280907,\n",
              " -0.048695698380470276,\n",
              " 0.05084334313869476,\n",
              " -0.0012932618847116828,\n",
              " -0.014733269810676575,\n",
              " -0.0942688137292862,\n",
              " -0.005923083983361721,\n",
              " 0.0548890121281147,\n",
              " -0.0027005928568542004,\n",
              " 0.026992907747626305,\n",
              " -0.00731872720643878,\n",
              " -0.06826119124889374,\n",
              " -0.02900216169655323,\n",
              " 0.004012713208794594,\n",
              " 0.013650557026267052,\n",
              " 0.02704375982284546,\n",
              " 0.03710830584168434,\n",
              " 0.033099979162216187,\n",
              " 0.01301198173314333,\n",
              " -0.05733863264322281,\n",
              " 0.025459110736846924,\n",
              " 0.024094557389616966,\n",
              " -0.007090229541063309,\n",
              " -0.025551943108439445,\n",
              " 0.036184437572956085,\n",
              " 0.038272250443696976,\n",
              " -0.027310671284794807,\n",
              " 0.027453413233160973,\n",
              " 0.038615234196186066,\n",
              " 0.02579406090080738,\n",
              " 0.05250363424420357,\n",
              " 0.022117899730801582,\n",
              " -0.05710281804203987,\n",
              " -0.0017957596573978662,\n",
              " 0.03591448813676834,\n",
              " -0.005846180021762848,\n",
              " -0.06997204571962357,\n",
              " 0.00024452630896121264,\n",
              " -0.010681462474167347,\n",
              " 0.06773526221513748,\n",
              " -0.005376582033932209,\n",
              " 0.022301286458969116,\n",
              " 0.022317348048090935,\n",
              " 0.012877714820206165,\n",
              " -0.04674927517771721,\n",
              " 0.05696335807442665,\n",
              " -0.01296178437769413,\n",
              " 0.016913650557398796,\n",
              " -0.053046829998493195,\n",
              " -0.002701016841456294,\n",
              " 0.003923126962035894,\n",
              " 0.03747446462512016,\n",
              " 0.11272288858890533,\n",
              " -0.0015829706098884344,\n",
              " -0.05584847927093506,\n",
              " 0.09707442671060562,\n",
              " -0.00024738904903642833,\n",
              " -0.03714948520064354,\n",
              " -0.04195793718099594,\n",
              " 0.009514124132692814,\n",
              " 0.019299393519759178,\n",
              " -0.03335732966661453,\n",
              " 0.0021547258365899324,\n",
              " 0.053686920553445816,\n",
              " -0.03058801032602787,\n",
              " -0.0028617610223591328,\n",
              " 0.03269273787736893,\n",
              " 0.02336142770946026,\n",
              " -0.018097469583153725,\n",
              " -0.020934492349624634,\n",
              " 0.03093210980296135,\n",
              " -0.008286625146865845,\n",
              " -0.029237965121865273,\n",
              " -0.03758196532726288,\n",
              " -0.02840360254049301,\n",
              " 0.053243815898895264,\n",
              " 0.010723110288381577,\n",
              " -0.020957577973604202,\n",
              " -0.022098371759057045,\n",
              " 0.06305725127458572,\n",
              " -0.023262832313776016,\n",
              " 0.01595097780227661,\n",
              " 0.00835984107106924,\n",
              " 0.07245082408189774,\n",
              " 0.008686445653438568,\n",
              " 0.0012503870530053973,\n",
              " 7.557651406386867e-05,\n",
              " 0.03862207755446434,\n",
              " -0.019229695200920105,\n",
              " 0.014497706666588783,\n",
              " 0.012569671496748924,\n",
              " -0.026799125596880913,\n",
              " 0.019178958609700203,\n",
              " 0.026653669774532318,\n",
              " -0.014713150449097157,\n",
              " -0.00043338595423847437,\n",
              " 0.08456723392009735,\n",
              " -0.062270551919937134,\n",
              " 0.008901653811335564,\n",
              " -0.0008224630146287382,\n",
              " -0.009016134776175022,\n",
              " 0.010196023620665073,\n",
              " -0.05758286267518997,\n",
              " 0.001213831827044487,\n",
              " -0.012950764037668705,\n",
              " 0.08539506793022156,\n",
              " -0.01374772097915411,\n",
              " 0.03781634569168091,\n",
              " -0.015076442621648312,\n",
              " -0.0145783182233572,\n",
              " -0.012429311871528625,\n",
              " -0.05112070590257645,\n",
              " 0.042674072086811066,\n",
              " -0.03859506547451019,\n",
              " 0.0258342158049345,\n",
              " -0.0033613459672778845,\n",
              " -0.008885742165148258,\n",
              " 0.009936174377799034,\n",
              " 0.008650175295770168,\n",
              " -0.030997151508927345,\n",
              " 0.02414288930594921,\n",
              " 0.019081875681877136,\n",
              " 0.021299712359905243,\n",
              " -0.0016012733103707433,\n",
              " -0.03776213154196739,\n",
              " -0.007063841447234154,\n",
              " -0.010149193927645683,\n",
              " 0.018930433318018913,\n",
              " -0.030712800100445747,\n",
              " -0.0070159053429961205,\n",
              " -0.016985133290290833,\n",
              " 0.07048439234495163,\n",
              " 0.004174362868070602,\n",
              " -0.0022258968092501163,\n",
              " -0.02214689739048481,\n",
              " 0.027761224657297134,\n",
              " 0.034946225583553314,\n",
              " -0.044282216578722,\n",
              " -0.034360796213150024,\n",
              " -0.03490037843585014,\n",
              " 0.018017347902059555,\n",
              " -0.04288153350353241,\n",
              " 0.08776484429836273,\n",
              " 0.036676447838544846,\n",
              " -0.004171433392912149,\n",
              " -0.023275645449757576,\n",
              " -0.07430888712406158,\n",
              " -0.05915144830942154,\n",
              " 0.09232326596975327,\n",
              " -0.025909466668963432,\n",
              " -0.048947375267744064,\n",
              " -0.04248259216547012,\n",
              " -0.008888361044228077,\n",
              " -0.03014891780912876,\n",
              " -0.04645727202296257,\n",
              " -0.012320748530328274,\n",
              " -0.05791699141263962,\n",
              " -0.031029148027300835,\n",
              " -0.008003050461411476,\n",
              " 0.06263463944196701,\n",
              " -0.0003443692403379828,\n",
              " -0.0023389095440506935,\n",
              " -0.024600928649306297,\n",
              " -0.012160244397819042,\n",
              " 0.024075577035546303,\n",
              " 0.04455995932221413,\n",
              " -0.034846968948841095,\n",
              " 0.003009699983522296,\n",
              " -0.006747885141521692,\n",
              " 0.033100686967372894,\n",
              " 0.017554784193634987,\n",
              " 0.0066912914626300335,\n",
              " -0.03815562650561333,\n",
              " 0.03287581354379654,\n",
              " 0.008438421413302422,\n",
              " 0.05949356034398079,\n",
              " 0.05250370502471924,\n",
              " -0.025399159640073776,\n",
              " -0.00804033875465393,\n",
              " -0.0951286181807518,\n",
              " 0.04880988597869873,\n",
              " -0.030327320098876953,\n",
              " -0.00582280196249485,\n",
              " 0.06371273845434189,\n",
              " -0.008379978127777576,\n",
              " -0.01847619190812111,\n",
              " 0.0033510157372802496,\n",
              " -0.06536964327096939,\n",
              " -0.007209788542240858,\n",
              " 0.0060051498003304005,\n",
              " 0.00125016737729311,\n",
              " 0.0346645750105381,\n",
              " -0.0015321788378059864,\n",
              " -0.0008062190026976168,\n",
              " 0.012339606881141663,\n",
              " 0.004700178746134043,\n",
              " -0.014207116328179836,\n",
              " 0.048131342977285385,\n",
              " -0.028085095807909966,\n",
              " 0.0396636538207531,\n",
              " -0.026388678699731827,\n",
              " 0.02602994255721569,\n",
              " 0.005051842425018549,\n",
              " 0.061865344643592834,\n",
              " 0.07961132377386093,\n",
              " -0.03165215626358986,\n",
              " -0.019245469942688942,\n",
              " 0.047423698008060455,\n",
              " 0.029522284865379333,\n",
              " 0.0305622685700655,\n",
              " -0.04864562675356865,\n",
              " -0.05137154087424278,\n",
              " -0.03016076795756817,\n",
              " -0.010218193754553795,\n",
              " 0.02187609300017357,\n",
              " 0.06728222966194153,\n",
              " -0.058545537292957306,\n",
              " -0.07691137492656708,\n",
              " -0.04078034684062004,\n",
              " 0.02178112603724003,\n",
              " 0.004406917840242386,\n",
              " 0.01251312531530857,\n",
              " -0.01934864930808544,\n",
              " -0.00024852779461070895,\n",
              " -0.027734138071537018,\n",
              " 0.044431790709495544,\n",
              " 0.02758478745818138,\n",
              " 0.044154103845357895,\n",
              " -0.03837814927101135,\n",
              " 0.032868776470422745,\n",
              " 0.009355633519589901,\n",
              " -0.007741476874798536,\n",
              " -0.024058016017079353,\n",
              " -0.02246076613664627,\n",
              " -0.004031325690448284,\n",
              " -0.036114875227212906,\n",
              " 0.058158028870821,\n",
              " 0.0031521052587777376,\n",
              " 0.03671975061297417,\n",
              " -0.026520084589719772,\n",
              " -0.06631795316934586,\n",
              " 0.10039965808391571,\n",
              " -0.002299437765032053,\n",
              " -0.011070421896874905,\n",
              " -0.027540046721696854,\n",
              " 0.0407177172601223,\n",
              " 0.06292594969272614,\n",
              " 0.032785814255476,\n",
              " 0.021106448024511337,\n",
              " -0.04404228925704956,\n",
              " -0.005727207753807306,\n",
              " 0.06395310908555984,\n",
              " -0.007708157878369093]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.embed_query(\"What's our Q1 revenue?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WgugmfH_n7Ce"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4-CpRVo1orfc",
        "outputId": "e6127037-f0ac-43a9-fd48-7c1f3af67d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(dir(vectorstore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X6Ju3n7qe9p",
        "outputId": "c88acffc-6313-4bdf-af2c-f981cd9bdd45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7cc2d6b16f20>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RfVZCk7qkx5",
        "outputId": "6f33448d-1e15-4872-91ee-b1d810bafecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='a0d90432-b8ac-4f22-8d45-93be317da7b4', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              " Document(id='6c1c4189-80d7-474e-95b1-6973af32c79c', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='8cb77b34-d26f-4335-a1f8-f3897ae654c9', metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
              " Document(id='7cd72c28-95aa-465d-ae06-36596dba0d71', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.similarity_search(\"amzing moives\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnE59oZ3q2DI",
        "outputId": "a7b3b4f9-48d4-4368-8609-a6d53c5e3871"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='a0d90432-b8ac-4f22-8d45-93be317da7b4', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              " Document(id='6c1c4189-80d7-474e-95b1-6973af32c79c', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='8cb77b34-d26f-4335-a1f8-f3897ae654c9', metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
              " Document(id='7cd72c28-95aa-465d-ae06-36596dba0d71', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.similarity_search(\"amzing moives\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUqH1ve5rCZM",
        "outputId": "f28b7cd1-5a2e-4758-d72a-5654f72ae480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(Document(id='a0d90432-b8ac-4f22-8d45-93be317da7b4', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              "  0.8218643665313721),\n",
              " (Document(id='6c1c4189-80d7-474e-95b1-6973af32c79c', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              "  1.1743354797363281),\n",
              " (Document(id='8cb77b34-d26f-4335-a1f8-f3897ae654c9', metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
              "  1.2683296203613281),\n",
              " (Document(id='7cd72c28-95aa-465d-ae06-36596dba0d71', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
              "  1.3072998523712158)]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.similarity_search_with_score(\"amzing moives\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_za7KHWzsXCG",
        "outputId": "2d384dc2-2b48-4f38-8597-d3f20b85b9ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='a0d90432-b8ac-4f22-8d45-93be317da7b4', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              " Document(id='6c1c4189-80d7-474e-95b1-6973af32c79c', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='8cb77b34-d26f-4335-a1f8-f3897ae654c9', metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
              " Document(id='7cd72c28-95aa-465d-ae06-36596dba0d71', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding = embeddings.embed_query(\"amzing moives\")# convert cat into vector\n",
        "\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSd8rCYWsqkr"
      },
      "source": [
        "# ***Retrievers***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVIOMM_5slYC",
        "outputId": "b4b1317d-facf-4369-a764-9e5a80515379"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[Document(id='6c1c4189-80d7-474e-95b1-6973af32c79c', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"python\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "daq2Zhl9teGk"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SWW2HBfvttjj"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qCadYDsNuSMi"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrDIi2tfuV74"
      },
      "source": [
        "# ***RAG***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "B_az4M6TuTZS"
      },
      "outputs": [],
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4YX9HGUvKKD",
        "outputId": "8c79c77c-7888-4382-d946-2acfb0031384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The provided context does not contain information about Python.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke(\"tell me python?\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW9BBiZ7vOgh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
